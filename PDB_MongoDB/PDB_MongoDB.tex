\documentclass[12pt]{article}
\usepackage[usenames, dvipsnames]{xcolor}
\usepackage{listings}

\definecolor{myGray}{rgb}{0.9,0.9,0.9}

\lstset{ %
  backgroundcolor=\color{myGray},   % choose the background color
  basicstyle=\footnotesize,        % size of fonts used for the code
  breaklines=true,                 % automatic line breaking only at whitespace
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{PineGreen},    % comment style
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  keywordstyle=\color{blue},       % keyword style
  stringstyle=\color{BrickRed},     % string literal style
}

\newcommand{\cmdline}[1]{\vspace{5mm} \noindent
\texttt{\$ #1}
\vspace{5mm}

}

\newcommand{\mdbcmdline}[1]{\vspace{5mm} \noindent
\texttt{$>$ #1}
\vspace{5mm}

}

\newcommand{\mdbdb}[1]{{\color{BlueViolet}\textbf{#1}}}
\newcommand{\mdbcol}[1]{{\color{Bittersweet}\textbf{#1}}}

\title{Using the PDB MongoDB in the Richardson Lab}
\author{Bradley J. Hintze}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduction}
Herein you will find various topics relating to the use of the MongoDB in the Richardson Lab including the MongoDB shell, updating the database, and python query scripts.
Note the following conventions for distinguishing command line types.
Command line arguments that begin with a \$ denote the Linux command line. e.g.

\cmdline{phenix.probe 1ubqH.pdb}
\noindent
Command line arguments that begin with a $>$ denote the MongoDB command line. e.g.

\mdbcmdline{show databases}

\noindent
Note that within the text of this document database names are in \mdbdb{blue} and collection names are in \mdbcol{dark orange}.

\section{Contents of the PDB MongoDB}
\label{sec:MongoDBContents}
There are two main databases that are relevant for most queries we are interested in running -- \mdbdb{top8000\_rota\_data} and \mdbdb{pdb\_info}.
The collections within the \mdbdb{top8000\_rota\_data} database are duplicates of tables from the original Top8000 SQL database on c3po maintained by Bradley during his dissertation years.
Collections within \mdbdb{top8000\_rota\_data} are listed in Table \ref{tab:T8kDB}.

\begin{table}[h]
\caption{Contents of \mdbdb{top8000\_rota\_data}}
\begin{tabular}{l|p{8cm}}
%  \hline
  \textbf{Collection} & \textbf{Contents} \\ \hline
  \mdbcol{rsc} & Real-space correlation data at the residue level. \\ \hline
  \mdbcol{top\_8000\_filtered\_src} & A list of the filtered residues which make up the Top8000 rotamer dataset. \\ 
   \mdbcol{versions\_2} & Homology clusters from the PDB. \\ \hline
\end{tabular}
\label{tab:T8kDB}
\end{table}

\noindent
The \mdbdb{pdb\_info} database contains new data Bradley tried to maintain after in his postdoc.
Some collections are not actively updated and a good project would be to come up with a way to keep these collections up to date.
Collections within \mdbdb{pdb\_info} are listed in Table \ref{tab:pdbinfoDB}.
\begin{table}[h]
\caption{Contents of \mdbdb{pdb\_info}}
\begin{tabular}{l|p{9cm}}
%  \hline
  \textbf{Collection} & \textbf{Contents} \\ \hline
  \mdbcol{experiment} & Has experimental data taken straight from PDBe. Actively updated using the update\_mongo script in lab\_scripts. \\ \hline
  \mdbcol{summary} & Has summary data taken straight from PDBe. Actively updated using the update\_mongo script in lab\_scripts. \\ \hline
   \mdbcol{pdb\_residues} & Comprehensive validation metrics on the residue level. Not actively updated. \\ \hline
   \mdbcol{residues\_colkeys} & Comprehensive validation metrics on the residue level. Not actively updated. I believe this is the one we want to keep up-to-date rather than \mdbcol{pdb\_residues} -- the difference being the colon separated '\_id' -- useful to do a quick look up. \\ \hline
   \mdbcol{rscc} & Real-space correlation info on the residue level. Not actively updated. Use \mdbcol{residues\_colkeys} instead. \\ \hline
   \mdbcol{file\_info} & Various PDB entry level data from on of my scripts. Not actively updated. \\ \hline
\end{tabular}
\label{tab:pdbinfoDB}
\end{table}

\section{Using the MongoDB shell}
Currently the MongoDB in the Richardson lab is maintained on caldera. 
To log into the shell you will need to ssh onto daneel.

\cmdline{ssh user@caldera\_ip\_addy}
\noindent
You may need to have permissions set up to do this -- Bradley can help you get that setup.
\noindent
Now you need to enter the MongoDB shell.
The MongoDB server should be running automatically as I set it up to start on start up.
To see if the server is running:

\cmdline{ps aux | grep mongo}
\noindent
\texttt{mongo 99 0.0 0.4 .../bin/mongod}

\vspace{5mm}
\noindent
If the sever is running you can enter the MongoDB shell. Use the rlab user :

\cmdline{mongo -u rlab -p}
\noindent
You will be asked fro the password for rlab, which you know.
You should now be in the shell.
There are two databases that you have access to,  \mdbdb{pdb\_info} and \mdbdb{top8000\_rota\_data}.
Most of the data on individual PDB entries are in the \mdbdb{pdb\_info} database.
Top8000 data is in the \mdbdb{top8000\_rota\_data} database.
\noindent
To use a given database:

\mdbcmdline{use pdb\_info}
\noindent
Now that you are using a particular database you can see what collections exist therein. 
You can think of a collection as an SQL table.
Unlike SQL tables, collections can differ in what info they hold (except for the '\_id' record).
e.g. a PDB entry in the 'experiment' collection will have \texttt{resolution} if 'experimental\_method' is 'X-ray diffraction' but not if it is 'Solution NMR'.
The nuances relating to differing record-schemas within a given collection is beyond the scope of this document but you should be aware of it. To view the collections:

\mdbcmdline{show collections\\
experiment\\
file\_info\\
pdb\_residues\\
residues\_colkeys\\
rscc\\
summary}

\subsection{Queries in the Shell Environment}
You can do queries in the MongoDB shell. 
This isn't where you will do production type work but it is a place to get an idea of what type of data a given collection holds.
It is also good for getting quick counts.
e.g. How many PDB entries were solved via X-ray diffraction?
So let's tackle this question.
Let's look for a record that has to do with the experimental method -- a good guess would be that this data is within the \mdbcol{experiment} collection in the \mdbdb{pdb\_info} database.
Assuming you are 'using' \mdbdb{pdb\_info} in the shell, you can enter a query that looks for just one record :

\mdbcmdline{db.experiment.findOne()}
\noindent
Note that you typically do not want to do \texttt{db.experiment.find()} as this will return every document in the collection -- similar to the following SQL query:

\vspace{5mm}
\noindent
\texttt{SELECT *\\
FROM experiment}

\vspace{5mm}
\noindent
which returns every column in the table. 
(Note that a 'column' in SQL space is essentially a 'document' in MongoDB space.)
However, its OK if you accidental issue \texttt{db.experiment.find()} in the shell as MongoDB returns just 20 documents at a time and asks if you'd like to see more.
When we issue the \texttt{db.experiment.findOne()} command we get one document and we get \textit{every} record in that document.
The returned document should be in JSON format and can be though of as a python dictionary -- a 'record' consists of a key and value.
The returned document should hold a record called \texttt{experimental\_method} and the value is a string.

\vspace{5mm}
\noindent
\texttt{"experimental\_method" : "Solution NMR"}

\vspace{5mm}
\noindent
We have to know the exact string for X-ray diffraction in order to query it but the one record we found returned "Solution NMR".
We can use \texttt{findOne} with a query.
Queries in MongoDB are just like JSON documents (of Python dictionaries).
Again, the different options for querying within MongoDB is beyond the scope of this document -- Google is here to help!
The query to find documents where "Solution NMR" is not the "experimental\_method" looks like \texttt{\{"experimental\_method":\{\$ne:"Solution NMR"\}\}}. \$ne stands for 'not equal'.
This query document is placed within the parens of \texttt{findOne} or \texttt{find}.

\mdbcmdline{db.experiment.findOne(\\
\{"experimental\_method":\{\$ne:"Solution NMR"\}\})}
\noindent
Here we have given \texttt{findOne} one argument -- the query. 
\texttt{findOne} actually takes two optional arguments, the second is a JSON document that tells the program what records to return.
To return just the "experimental\_method" issue this:

\mdbcmdline{db.experiment.findOne(\\
\{"experimental\_method":\{\$ne:"Solution NMR"\}\}, \\
\{"experimental\_method":1\})
}

\noindent
Note that the '\_id' record is returned by default.
You can suppress this by issuing:

\mdbcmdline{db.experiment.findOne(\\
\{"experimental\_method":\{\$ne:"Solution NMR"\}\}, \\
\{"experimental\_method":1,"\_id":0\})
}
\noindent

Or try the \texttt{find} function.

\mdbcmdline{db.experiment.find(\\
\{"experimental\_method":\{\$ne:"Solution NMR"\}\}, \\
\{"experimental\_method":1\})
}

\noindent
which will print out the first 20 results an ask if you want to see more.

\vspace{5mm}
\noindent
You can also count.
To see how many entries are in \mdbcol{experiment}, issue :

\mdbcmdline{db.experiment.count() \\
118970}

\noindent
As of the date this was written, there are 118,9870 entries in \mdbcol{experiment}.
To see how many of these were solved via X-ray diffraction enter the query as we did before when using \texttt{findOne} and \texttt{find}.

\mdbcmdline{db.experiment.count(\\
\{"experimental\_method" : "X-ray diffraction"\}) \\
106306}

\noindent
As of the date this was written, there are 106,306 entries in the collection that were solved via X-ray diffraction.


\section{Interacting with MongoDB with Python}
\subsection{Installing pymongo}
In order to interact with the MongoDB with Python you need to install pymongo.
I recommend installing from source so you install the dependencies with you PHENIX python.
For up-to-date instructions, consult Google.
The essentials are:

\vspace{5mm}
\noindent
\texttt{\$ git clone / \\
\indent
git://github.com/mongodb/mongo-python-driver.git pymongo}

\noindent
\texttt{\$ cd pymongo/}

\noindent
\texttt{\$ python setup.py install}

\vspace{5mm}
\noindent
If you want pymongo available with PHENIX tools, ensure you source PHENIX before doing the above install.

\newpage
\subsection{PyMongo}
Interacting with Mongo in python is pretty intuitive.
First you need to connect and set the database.
To do so, the safest way is to create an ssh tunnel to the machine that has the database (and has the mongod deamon running) from your local machine.
The way we create a tunnel is forthcoming to this document.
Once the tunnel is established, you can run the python commands below.

\begin{lstlisting}[language=python]
from pymongo import MongoClient

# connect to MongoDB on daneel
uri = "mongodb://user:psw@127.0.0.1/?authSource=test"
client = MongoClient(uri)

# get desired database
database = 'pdb_info'
db = getattr(client,database)
\end{lstlisting}

\noindent
Now we're ready to query the database called pdb\_info much like we did in the shell.
This time queries are native Python dictionaries.
A count query looks like:

\begin{lstlisting}[language=python]
query = {"experimental_method":"X-ray diffraction"}
n = db.experiment.count(query)
\end{lstlisting}

\noindent
Now we can put it all together.
%\newpage

\begin{lstlisting}[language=python]
from pymongo import MongoClient
import getpass

# get Mongo credentials
msg = "Please enter your Mongo username (probably rlab):"
user = raw_input(msg)
print "Please enter the Mongo password for %s:" % user
psw = getpass.getpass()

# connect to MongoDB (ensure that you setup the ssh tunnel correctly or
# it will look for the mongo deamon on your local machine.)
uri = "mongodb://%s:%s@127.0.0.1/?authSource=test"
client = MongoClient(uri% (user,psw))

# get desired database
database = 'pdb_info'
db = getattr(client,database)
# or this works:
# db = client.pdb_info

# Now you're ready to query the database 
expmet = "X-ray diffraction"
query = {"experimental_method" : expmet}
print "Your query is:\n  %s" % query
n = db.experiment.count(query)
msg = 'There are %i entries in the expriment collection that were solved via %s'
print msg % (n,expmet)
\end{lstlisting}

\noindent
Now let's get a list of PDBs that are above 1 \AA{} resolution.
Here I'll just list the first 10.

\begin{lstlisting}[language=python]
high_resolution = 1.0
query = {"experimental_method" : "X-ray diffraction"}
query['resolution'] = {'$lte':high_resolution}
projection = {"_id":1}
n = 10
pdbs = db.experiment.find(query, projection)
msg = "Here are the first %i PDBs with a resolution above %.1f"
print msg % (n,high_resolution)
for i,d in enumerate(pdbs) :
  print d['_id']['pdb_id']
  if i > n : break
\end{lstlisting}

\noindent
Pretty easy.
Any questions?
Ask Google or Bradley.
Also note that there are more examples (real ones I used to get various data for the lab) on Github under lab\_scripts.
These are a bit more complicated (e.g. the connection to the database is its own object) but all of the essential elements are there.

\section{Updating the Database}

There are three collections that are used the most which require updating if you want to capture the most recently deposited structures in your queries. The collections are \mdbcol{experiment}, \mdbcol{summary} and \mdbcol{residues\_colkeys}.

\subsection{Updating \mdbcol{experiment} and \mdbcol{summary}}

Updating the \mdbcol{experiment} and \mdbcol{summary} collections in the \mdbdb{pdb\_info} database is rather straightforward since the JSON document that make up a given entry comes straight from the PDB using the PDBe python API. The scripts for doing this are in lab\_scripts (which is available on Github) in the directory called 'update\_mongo'. The script requires an updated list of PDB codes. We get this using our local PDB mirror on muscle.

\begin{itemize}
\item On muscle, issue \\
\indent
\$ find /home/pdber/Desktop/PdbData/ -name '*.ent.gz' /\\ $>$ allpdbs.l
\item Copy allpdbs.l to lab\_scripts/update\_mongo (allpdbs.l is in .gitignore) on your machine or wherever you're running this.
\item Now you're ready to update.
\end{itemize}

\noindent
Now that you have allpdbs.l we can update. Make sure that you are in\\lab\_scripts/update\_mongo. The script that runs the updates is called\\ \texttt{update\_pdbe\_collections.py}. Ensue that you are using a python that has pymongo available to it. You can get help by:

\cmdline{python update\_pdbe\_collections.py -h}

\noindent
When running update\_pdbe\_collections.py you will be asked for a username a password. for now us 'bhintze' and the corresponding password.

\vspace{5mm}
\noindent
By default, the script updates \mdbcol{experiment}. To do this simply do:

\cmdline{python update\_pdbe\_collections.py}

\noindent
To update \mdbcol{summary} simply do:

\cmdline{python update\_pdbe\_collections.py -t summary}

\subsection{Updating \mdbcol{residues\_colkeys}}

There are 3 steps to update \mdbcol{residues\_colkeys}:
\begin{itemize}
\item Get pdbs currently in \mdbcol{residues\_colkeys} -- file should be 1 code per line.
\item Setup and run \texttt{run\_mongo\_validation.py} on the cluster with the two PDB lists.
\item Enter the JSON output from \texttt{run\_mongo\_validation.py} into the MongoDB. 
\end{itemize}

\subsubsection*{Get pdbs currently in \mdbcol{residues\_colkeys}}
In lab\_scripts/mongo\_queries/update\_mongo there is a script called\\ \texttt{get\_list\_of\_pdbs\_in\_collection.py} that does all the work for you. You can specify an output file which is ready to use when running \\ \texttt{run\_mongo\_validation.py}. NOTE: when running this, using the '.l' extention will prevent an accidental commit to git as '*.l' is in .gitignore. Also, the name should be residues\_colkeys\_pdbs.l as scripts in later steps will expect this name.

\vspace{5mm}
\noindent
\texttt{\$ python get\_list\_of\_pdbs\_in\_collection.py residues\_colkeys\\-o residues\_colkeys\_pdbs.l}

\vspace{5mm}
\noindent
\texttt{get\_list\_of\_pdbs\_in\_collection.py} is intended to get a list of missing PDBs from any collection in \mdbdb{pdb\_info} but functionality for collections other than \mdbcol{residues\_colkeys} may not be programmed yet.

\subsubsection*{Setup and run \texttt{run\_mongo\_validation.py} on the cluster}
This is by far the most complicated part of the process. This gets all validation data for each residue in each PDB. The script that does this is in PDB\_mongodb, a RLab GitHub repository. The script that sets up the environment to run the PDB\_mongodb rutine is in lab\_scripts, a seperate RLab GitHub repository. In the previous step you created residues\_colkeys\_pdbs.l that has the PDB codes in \mdbcol{residues\_colkeys}. Now that we have that we are ready for the next step.

\vspace{5mm}
\noindent
Copy over residues\_colkeys\_pdbs.l to an unmodified\\lab\_scripts/mongo\_queries/update\_mongo/cluster\_scripts.  

\vspace{2mm}
\noindent
\texttt{\$ cp residues\_colkeys\_pdbs.l cluster\_scripts/}

\vspace{5mm}
\noindent
Copy over this cluster\_scripts directory to LBL.  

\vspace{2mm}
\noindent
\texttt{\$ rsync -av cluster\_scripts/ lbl.domain:/my/path/run\_20161122}

\vspace{5mm}
\noindent
ssh to LBL, go to /my/path/run\_20161122 and run setup.

\vspace{2mm}
\noindent
\texttt{\$ cd /my/path/run\_20161122}

\noindent
\texttt{\$ ./setup.sh}

\vspace{5mm}
\noindent
The setup script creates the requsite directories for qsub and gets a list of needed PDBs by enumerating through the structure factors directory in the PDB mirror on the LBL cluster and eliminating pdbs already in the DB (i.e. PDBs in residues\_colkeys\_pdbs.l). This writes a file called pdbs\_to\_be\_done.l used by the qsub scripts that run \texttt{run\_mongo\_validation.py}. At the end of running, the setup script tells you the number of pdbs in pdbs\_to\_be\_done.l and the command to issue to submit your job to the que. e.g.

\vspace{2mm}
\noindent
\texttt{\$ qsub -t 1-N qsub.sh}

\vspace{2mm}
\noindent
where N is the number of pdbs in pdbs\_to\_be\_done.l. YOU NEED TO BE ON CHEVY TO DO THIS!

\vspace{10mm}
\noindent
Useful qsub commands:
\begin{itemize}
  \item \texttt{libtbx.sge\_qstat\_counts} -- see jobs and who is running the.
  \item \texttt{libtbx.sge\_available\_slots} -- guess what this does.
\end{itemize}
\subsubsection*{Insert the JSON output from \texttt{run\_mongo\_validation.py} into the MongoDB}

Inserting JSON documents into MongoDB is super easy, it just takes a very long command. Before that though, you'll need to get the data from the LBL cluster. When we ran \texttt{run\_mongo\_validation.py} at LBL we created a directory called \texttt{val\_out} -- this is where ther data was output. We need to copy \texttt{val\_out} to your local machine:

\vspace{2mm}
\noindent
\texttt{\$ rsync -av lbl.domain:/my/path/run\_20161122/val\_out .}

\vspace{5mm}
\noindent
Now that we have the data, we can now insert the data into the MongoDB. Ensure you have established the ssh tunnel and then run:

\vspace{2mm}
\noindent
\texttt{\$ find val\_out/ -name "*.validate" -exec mongoimport --db pdb\_info --collection residues\_colkeys  --file '\{\}' --username bhintze --password youknow --authenticationDatabase test $\backslash$;}

\vspace{5mm}
\noindent
Of course, you'll need to replace 'youknow' with the actual password.
\end{document}